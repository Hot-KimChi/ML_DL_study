{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c1735b",
   "metadata": {},
   "source": [
    "---\n",
    "- 알고리즘에 따라서 스케일에 영향을 받을 수도 않받을 수도 있음.(특성 간의 영향)\n",
    "  - 영향받는 알고리즘: 경사하강법(gradient descent), K-최근접 이웃\n",
    "  - 영향을 않받는 알고리즘: 결정트리와 랜덤 포레스트\n",
    "- 대부분의 머신 러닝과 최적화 알고리즘은 특성의 스케일이 같을 때 훨씬 성능이 좋다.\n",
    "- 최적화 알고리즘\n",
    "  - 1) 정규화(normalization)\n",
    "    - [0, 1]범위에 맞추어 사용\n",
    "    - min-max scaling\n",
    "    - 단점: 데이터셋에 비정상적으로 아주 큰 값이나 아주 작은 값이 들어 있을 때 다른 샘플들을 좁은 구간에 촘촘하게 모아 버림    \n",
    "\n",
    "  $x^{(i)}_{norm} = \\dfrac{x^{(i)}-x_{min}}{x_{max}-x_{min}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3aed0",
   "metadata": {},
   "source": [
    "- 최적화 알고리즘\n",
    "  - 2) 표준화(standardization)\n",
    "    - 경사 하강법같은 최적화 알고리즘에서 널리 사용.\n",
    "    - 특성의 평균 0에 맞추고 표준편차를 1로 만들어 정규분포와 같은 특징을 가지도록 설계\n",
    "    - 이상치 정보가 유지되기에 아주 큰 값이나 / 아주 작은 값에 영향을 덜 받는다.\n",
    "  \n",
    "  $x^{(i)}_{std} = \\dfrac{x^{(i)}-\\mu_x}{\\sigma_x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479fe23",
   "metadata": {},
   "source": [
    "- 최적화 알고리즘\n",
    "  - 3) RobustScaler\n",
    "    - 이상치가 많이 포함된 작은 데이터셋을 다룰 때 특히 도움.\n",
    "    - 극단적인 값과 이상치에 영향을 덜 받는다.\n",
    "    - 과대적합(overfitting)이 되기 쉽다면, RobustScaler가 도움.\n",
    "    - 중간값(q2: 50%) 값을 빼고 1사분위(q1: 25%)와 3사분위(q3: 75%)의 차이로 나누어 데이터의 스케일을 조정\n",
    "    \n",
    "  $ x_{robust}^{(i)} = \\dfrac{x^{(i)} - q_2}{q_3 - q_1}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
