{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d99965f-e681-4120-8998-473e9cbfbe42",
   "metadata": {},
   "source": [
    ">### 10.3_순환 신경망 이해하기\n",
    "- 밀집 연결 모델, 컨브넷처럼 모든 신경망의 특징은 메모리가 없다.\n",
    "- 네트워크에 주입되는 입력은 개별적으로 처리되며 입력 간에 유지되는 상태가 없다.\n",
    "- 그렇기에 시계열 데이터 포인트를 처리하려면 네트워크에 전체 시퀀스를 주입해야 한다.\n",
    "    - 즉 5일치 데이터를 펼쳐서 하나의 큰 벡터로 만들어서 처리(피드포워드 네트워크) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ecd33-bb44-4e97-b665-3f49b72a9046",
   "metadata": {},
   "source": [
    ">### 어떤 길이의 시퀀스도 처리할 수 있는 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8098d1-272d-41a9-a370-71af16812727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "num_features = 14\n",
    "inputs = keras.Input(shape=(None, num_features))\n",
    "outputs = layers.SimpleRNN(16)(inputs)\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1771c-264e-4f17-b249-276451edcd0a",
   "metadata": {},
   "source": [
    ">### 마지막 출력 스텝만 반환하는 RNN층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99f0957-0e2d-4cf7-b57b-e9d498daa575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "num_features = 14\n",
    "steps = 20\n",
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "outputs = layers.SimpleRNN(16, return_sequences=False)(inputs)\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6818552-52d0-4b0c-8163-db3b4ed0d149",
   "metadata": {},
   "source": [
    ">### 전체 출력 시퀸스 반환하는 RNN층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547b4b16-b7cb-4c83-ad45-0d1425904c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 20, 16)\n"
     ]
    }
   ],
   "source": [
    "num_features = 14\n",
    "steps = 20\n",
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "outputs = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f54d99-d5ba-438a-a069-56b76bb227c8",
   "metadata": {},
   "source": [
    ">### 스태킹 RNN층\n",
    "- 네트워크 표현력 증가시키기 위해, 여러 개의 순환층을 차례로 쌓는 것이 유용할 때가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f42528d-65f5-4ff5-80b3-c7faf97710fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "num_features = 14\n",
    "steps = 20\n",
    "inputs = keras.Input(shape=(steps, num_features))\n",
    "x = layers.SimpleRNN(16, return_sequences=True)(inputs)\n",
    "x = layers.SimpleRNN(16, return_sequences=True)(x)\n",
    "outputs = layers.SimpleRNN(16)(x)\n",
    "\n",
    "print(outputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
